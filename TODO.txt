Add the following to the GUI:

1. for each function, a checkmark that upon activation also makes an event out of the exit point of the function. It adds letters, which is not so good, but it might be useful to distinguish between, say
f() {
g();
h();
}

And
f() {
g()
}
g() {
h();
}

Goto-instrument supports adding events at exit points.

2. Slicing: with this option, 'f' will be removed from the alphabet if it is not in the slice of the assertion.

3. positive pre-checks should be added to the positive-queries cache. 

4. Spurious traces: 
Currently with the trap mechanism we do not remove all such traces, and also we may delay convergance. 
For example, a word a,b,c,assert
There is a branch after b that lets the program either go to c and assert, or just exit the program. If it exits the program, the trap nondeterministically chooses c,assert and declares this word as a negaive feedback. Despite the fact that we could have converged at that point (answer yes to the conjecture). libalf does not know if we answer with a negative or positive feedback - it just produces membership queries. But what if this is not really a counterexample? i.e., then all the membership queries are supposed to be consistent with the current automaton. This seems to contradict an invariant of L*, namely that the feedback changes the conjecture. 
It seems that as long as there are words shorter than the bound that are accepted by A but are not supported yet by the assumptions, then we will not converge. What happens is that those words serve as feedback, asked as a membership query, and only then added as an assumption.

Possible solution: do not do it via a feedback to the conjecture. It other words: when we find a negative feedback via the trap, ask separately a membership query about this word, and if it is in the language, then repeat with the same conjecture but with an additional assumption. This is only true about feedback from the trap. 'normal' negative feedback is indeed a counterexample.

* better solution: remove trap mechanism all together. then after convergence 1) intersect A with the control-flow graph, and 2) go over all words up to length 'bound' that we do not have a positive entry forthem in the cache, and pose a membership query. If it is negative then remove it from the language. 

5. Limiting tests to those that have a loop bound. 



6. Structure the log files better, perhaps via a dictionary struture (only keeping suffixes for words with common prefixes). Can also create an “automaton” (which is inherintly loop-free) from the log file - then, compute a cross-product of this automaton with a conjecture to identify feedbacks. 



7. Updating the internal table constructed by L* for better lazy learning. 

8. With decision-tree learning (e.g. the ID3 algorithm or others), find a small (or smallest, but this is np-hard) set of events that separate faulty executions from correct ones (currently the logs are projected to a predefined set of events. We can start with a large set ('all functions and branches') and let it find the attributes that make the sepration. 

9. Permit as part of the GUI to remove letters. This will create a non-det automaton, which then has to be re-minimized (and possibly determinized).

10. Automatically add functions up to a given distance (on the call graph, or on its undirected version) from the assert.